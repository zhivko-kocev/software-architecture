# Домашна 1: Pipe and Filter архитектурата

Оваа апликација обезбедува автоматизирано превземање, трансформирање и складирање на дневни податоци од Македонската берза, покривајќи најмалку последниве 10 години за сите валидни издавачи. Апликацијата користи архитектурен модел *Pipe and Filter* за ефикасно и структуирано процесирање на податоците.

## Мерења на Перформансите

> Забелешка: Овие мерења се правени врз сите можни трансакции односно 355,324 трансакции а според наша груба проценка доколку се исфилтрираат само тие 28,337 трансакции кои што имаат вредности за минимална и максимална трансакција би било потребно помалку од 20 секунди!!! а за апдејтирање на само еден месец помалки од 5 секунди!!!.

**Извршени се мерења за брзината на скрејпинг и обработката на податоците во различни сценарија**:

- **Прва иницијализација**: Кога базата на податоци е целосно празна, просечното време за извршување е околу 100 секунди (базирано на 10 мерења).
- **Ажурирање на податоци**: Кога базата содржи податоци, но не е ажурирана еден месец, просечното време за ажурирање е околу 6 секунди (базирано на 10 мерења).

Фолдерот benchmarking содржи директориуми first_scrape и second_scraping со сите мерења. Базата на податоци со над 555 илјади редови се наоѓа во директориумот database, што ја истакнува обемноста и значењето на автоматизираниот процес за ажурирање.

## Структура на проектот

```
Домашна 1/
├── benchmarking/
├── stockmarket/
|   ├── database/
│   ├── models/
│   ├── spiders/
│   ├── config.py
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── utils.py
├── script.py
└── scrapy.cfg
```

### Опис на компонентите

1. **models/** - Овој директориум содржи дефиниции на SQLAlchemy модели кои ја претставуваат структурата на базата на податоци. Овие модели ги дефинираат табелите и релациите во базата.

2. **spiders/** - Овој директориум содржи Scrapy пајаци (spiders) кои се одговорни за скрејпирање на податоците од веб-сајтот на Македонската берза. Секој пајак дефинира како да се навигира низ веб-страниците и кои податоци да се извлечат.

3. **config.py** - Овој фајл содржи конфигурациски параметри за проектот, како што се URL-и, патеки до фајлови, или други константи кои се користат низ целиот проект.

4. **items.py** - Овој фајл дефинира Scrapy Item класи кои ја претставуваат структурата на податоците кои се скрејпираат. Овие Item-и служат како контејнери за извлечените податоци пред да бидат процесирани или зачувани.

5. **middlewares.py** - Овој фајл содржи Scrapy middleware-и кои можат да модифицираат барања или одговори во процесот на скрејпирање. Тие можат да се користат за додавање на custom функционалности во процесот на скрејпирање.

6. **pipelines.py** - Овој фајл дефинира Scrapy pipeline-и кои се користат за процесирање на податоците откако ќе бидат извлечени од пајаците. Тука може да се имплементира логика за чистење на податоците, валидација, или зачувување во базата на податоци.

7. **settings.py** - Овој фајл ги содржи конфигурациските поставки за Scrapy проектот, вклучувајќи поставки за пајаците, pipeline-ите, middleware-ите, и други Scrapy-специфични опции.

8. **utils.py** - Овој фајл содржи помошни функции кои се користат низ целиот проект, како што се функции за форматирање на датуми, конверзија на валути, или други општи utility функции.

9. **script.py** - Овој фајл во root директориумот е главниот скрипт кој ја оркестрира целата апликација, иницирајќи го процесот на скрејпирање и управувајќи со целокупниот тек на податоците низ системот.

10. **scrapy.cfg** - Ова е конфигурацискиот фајл за Scrapy проектот кој специфицира основни поставки за проектот и може да содржи информации за deployment.

11.  **database** - Тука е зачувана базата со сите трансакции.

Оваа структура ја следи стандардната Scrapy архитектура, додека интеграцијата со SQLAlchemy овозможува ефикасно складирање и управување со податоците во релациона база. Комбинацијата на овие технологии со Pipe and Filter архитектурата овозможува создавање на робустен и скалабилен систем за автоматизирано прибирање и анализа на податоци од Македонската берза.

## Главни карактеристики

- **Скрејпинг на податоци**: Користи Scrapy за автоматско прибирање на дневните податоци за издавачите на Македонската берза.
- **Pipe and Filter**: Обработка на податоците преку повеќе независни филтри, што го прави процесот ефикасен и лесен за одржување.
- **Автоматизирано управување со податоци**: Системот проверува кои податоци недостигаат и ги ажурира само тие, со што се обезбедува актуелност на базата.

## Поставки и Инсталација

```bash
git clone https://github.com/your-repo/macedonian-stock-analysis
cd Домашна\ 1/
python3 -m venv .venv
# активирајте го .venv (различно е на секој оперативен систем)
pip install -r requirements.txt
python3 script.py
```

### Барања

- **Python**: Верзија 3.8 или понова
- **Scrapy**: За скрејпинг на податоците од веб-сајтот на Македонската берза
- **SQLAlchemy**: За полесна обработка и складирање на обработените податоци
